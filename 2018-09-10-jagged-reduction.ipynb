{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jagged reduction\n",
    "\n",
    "Given a jagged array, we want to compute a reduction (e.g. `sum` or `max`) as quickly as possible. We'll study the naive sequential algorithm, Jaydeep's modified Hillis-Steele on GPU and AVX-512. As a further modification, we replace the offsets-driven gather with a parents-driven scatter, since the extra pass gather was found to be dominant over the reduction itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: prepare data\n",
    "\n",
    "The jagged datasets are Gaussian random numbers in Poisson-distributed groups, a different dataset for each Poisson-average group size. To make debugging easier, the Gaussian numbers will be 1 +- 0.01 (the sum will always be approximately equal to the count), and there will be 15 samples with logarithmically spaced Poisson-averages:\n",
    "\n",
    "    0.3 0.5 1.0 2.0 3.0 5.0 10.0 20.0 30.0 50.0 100.0 200.0 300.0 500.0 1000.0\n",
    "\n",
    "This is about 20 GB (15 GB inputs + 5 GB outputs), and we'll cache them on disk (in `/tmp/DATA`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasksize = 100000000\n",
    "\n",
    "def make_dataset(averagesize, location=\"/tmp/DATA\"):\n",
    "    if not os.path.exists(location):\n",
    "        os.mkdir(location)\n",
    "    counts = numpy.random.poisson(averagesize, int(numpy.ceil(tasksize / averagesize)))\n",
    "    offsets = numpy.empty(len(counts) + 1, dtype=numpy.int32)\n",
    "    offsets[0] = 0\n",
    "    numpy.cumsum(counts, out=offsets[1:])\n",
    "    del counts\n",
    "    with open(os.path.join(location, \"offsets-{}\".format(averagesize)), \"wb\") as f:\n",
    "        offsets.tofile(f)\n",
    "\n",
    "    parents = numpy.zeros(len(content), dtype=numpy.int32)\n",
    "    numpy.add.at(parents, offsets[offsets != offsets[-1]][1:], 1)\n",
    "    numpy.cumsum(parents, out=parents)\n",
    "    with open(os.path.join(location, \"parents-{}\".format(averagesize)), \"wb\") as f:\n",
    "        parents.tofile(f)\n",
    "    del parents\n",
    "    \n",
    "    content = numpy.random.normal(1, 0.01, offsets[-1]).astype(numpy.float32)\n",
    "    with open(os.path.join(location, \"content-{}\".format(averagesize)), \"wb\") as f:\n",
    "        content.tofile(f)\n",
    "    del content\n",
    "    del offsets\n",
    "\n",
    "averagesizes = 0.3, 0.5, 1.0, 2.0, 3.0, 5.0, 10.0, 20.0, 30.0, 50.0, 100.0, 200.0, 300.0, 500.0, 1000.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for averagesize in averagesizes:\n",
    "    make_dataset(averagesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(averagesize, location=\"/tmp/DATA\"):\n",
    "    offsets = numpy.fromfile(open(os.path.join(location, \"offsets-{}\".format(averagesize))),\n",
    "                             dtype=numpy.int32)\n",
    "    parents = numpy.fromfile(open(os.path.join(location, \"parents-{}\".format(averagesize))),\n",
    "                             dtype=numpy.int32)\n",
    "    content = numpy.fromfile(open(os.path.join(location, \"content-{}\".format(averagesize))),\n",
    "                             dtype=numpy.float32)\n",
    "    return offsets, parents, content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential algorithm\n",
    "\n",
    "This is the natural algorithm, stepping through jagged subcollections in a doubly nested for loop. We also use it to define the \"correct\" output. We'll study two such algorithms, `sum` and `max`.\n",
    "\n",
    "The `-O3` optimization and `-ftree-vectorize` flags are on, though this loop can't be vectorized because of the loop-carried dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -I. -c-O3 -c-ftree-vectorize\n",
    "\n",
    "from libc.stdint cimport int32_t\n",
    "from libc.math cimport INFINITY\n",
    "\n",
    "cdef extern from \"\":\n",
    "    \"\"\"\n",
    "void sequential_sum_impl(int32_t len_offsets, int32_t* offsets, float* content, float* output) {\n",
    "    for (int i = 0;  i < len_offsets - 1;  i++) {\n",
    "        output[i] = 0.0;\n",
    "        for (int j = offsets[i];  j < offsets[i + 1];  j++) {\n",
    "            output[i] += content[j];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void sequential_max_impl(int32_t len_offsets, int32_t* offsets, float* content, float* output) {\n",
    "    for (int i = 0;  i < len_offsets - 1;  i++) {\n",
    "        output[i] = -INFINITY;\n",
    "        for (int j = offsets[i];  j < offsets[i + 1];  j++) {\n",
    "            if (content[j] > output[i]) {\n",
    "                output[i] = content[j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "    void sequential_sum_impl(int32_t len_offsets, int32_t* offsets, float* content, float* output)\n",
    "    void sequential_max_impl(int32_t len_offsets, int32_t* offsets, float* content, float* output)\n",
    "\n",
    "def sequential_sum(offsets, parents, content, output):\n",
    "    sequential_sum_impl(len(offsets),\n",
    "                        <int32_t*>(<size_t>offsets.ctypes.data),\n",
    "                        <float*>(<size_t>content.ctypes.data),\n",
    "                        <float*>(<size_t>output.ctypes.data))\n",
    "\n",
    "def sequential_max(offsets, parents, content, output):\n",
    "    sequential_max_impl(len(offsets),\n",
    "                        <int32_t*>(<size_t>offsets.ctypes.data),\n",
    "                        <float*>(<size_t>content.ctypes.data),\n",
    "                        <float*>(<size_t>output.ctypes.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def define_correct(averagesize, location=\"/tmp/DATA\"):\n",
    "    offsets, parents, content = get_dataset(averagesize, location=location)\n",
    "    output = numpy.empty(len(offsets) - 1, dtype=numpy.float32)\n",
    "    sequential_sum(offsets, parents, content, output)\n",
    "    with open(os.path.join(location, \"sum-{}\".format(averagesize)), \"wb\") as f:\n",
    "        output.tofile(f)\n",
    "    sequential_max(offsets, parents, content, output)\n",
    "    with open(os.path.join(location, \"max-{}\".format(averagesize)), \"wb\") as f:\n",
    "        output.tofile(f)\n",
    "    del offsets, parents, content, output\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.5\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "5.0\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "50.0\n",
      "100.0\n",
      "200.0\n",
      "300.0\n",
      "500.0\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "for averagesize in averagesizes:\n",
    "    print(averagesize)\n",
    "    define_correct(averagesize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure time\n",
    "\n",
    "We'll use wall time of 3 repetitions, not counting data-loading or memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure(averagesize, run, times=10, location=\"/tmp/DATA\"):\n",
    "    offsets, parents, content = get_dataset(averagesize, location=location)\n",
    "    output = numpy.empty(len(offsets) - 1, dtype=numpy.float32)\n",
    "    cumulative = 0.0\n",
    "    for i in range(times):\n",
    "        start = time.time()\n",
    "        run(offsets, parents, content, output)\n",
    "        cumulative += time.time() - start\n",
    "    del offsets, parents, content, output\n",
    "    gc.collect()\n",
    "    return tasksize * times * 1e-6 / cumulative   # MHz in number of particles (not events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "sum_rates = pandas.DataFrame(index=averagesizes, columns=[\"sequential\"])\n",
    "max_rates = pandas.DataFrame(index=averagesizes, columns=[\"sequential\"])\n",
    "sum_rates.index.name = \"average number of items per group\"\n",
    "max_rates.index.name = \"average number of items per group\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for averagesize in averagesizes:\n",
    "    print(\"sum\", averagesize)\n",
    "    sum_rates.loc[averagesize, \"sequential\"] = measure(averagesize, sequential_sum)\n",
    "for averagesize in averagesizes:\n",
    "    print(\"max\", averagesize)\n",
    "    max_rates.loc[averagesize, \"sequential\"] = measure(averagesize, sequential_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sum_rates.plot(logx=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_rates.plot(logx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential algorithm 2: scatter from parents\n",
    "\n",
    "The first sequential algorithm determined which items belong in which group from the `offsets` array, but it could have made that determination from the `parents` array. The `parents` array is aligned with `content` and will be crucial to the vectorized algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -I. -c-O3 -c-ftree-vectorize\n",
    "\n",
    "from libc.stdint cimport int32_t\n",
    "from libc.math cimport INFINITY\n",
    "\n",
    "cdef extern from \"\":\n",
    "    \"\"\"\n",
    "void sequential2_sum_impl(int32_t len_offsets, int32_t len_parents, int32_t* parents, float* content, float* output) {\n",
    "    for (int i = 0;  i < len_offsets - 1;  i++) {\n",
    "        output[i] = 0.0;\n",
    "    }\n",
    "    int32_t lastparent = -1;\n",
    "    float cumulative = 0.0;\n",
    "    int i;\n",
    "    for (i = 0;  i < len_parents;  i++) {\n",
    "        if (lastparent != -1  &&  lastparent != parents[i]) {\n",
    "            output[lastparent] = cumulative;\n",
    "            cumulative = 0.0;\n",
    "        }\n",
    "        cumulative += content[i];\n",
    "        lastparent = parents[i];\n",
    "    }\n",
    "    if (lastparent != -1) {\n",
    "        output[lastparent] = cumulative;\n",
    "    }\n",
    "}\n",
    "\n",
    "void sequential2_max_impl(int32_t len_offsets, int32_t len_parents, int32_t* parents, float* content, float* output) {\n",
    "    for (int i = 0;  i < len_offsets - 1;  i++) {\n",
    "        output[i] = -INFINITY;\n",
    "    }\n",
    "    int32_t lastparent = -1;\n",
    "    float cumulative = -INFINITY;\n",
    "    int i;\n",
    "    for (i = 0;  i < len_parents;  i++) {\n",
    "        if (lastparent != -1  &&  lastparent != parents[i]) {\n",
    "            output[lastparent] = cumulative;\n",
    "            cumulative = -INFINITY;\n",
    "        }\n",
    "        if (content[i] > cumulative) {\n",
    "            cumulative = content[i];\n",
    "        }\n",
    "        lastparent = parents[i];\n",
    "    }\n",
    "    if (lastparent != -1) {\n",
    "        output[lastparent] = cumulative;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "    void sequential2_sum_impl(int32_t len_offsets, int32_t len_parents, int32_t* parents, float* content, float* output)\n",
    "    void sequential2_max_impl(int32_t len_offsets, int32_t len_parents, int32_t* parents, float* content, float* output)\n",
    "\n",
    "def sequential2_sum(offsets, parents, content, output):\n",
    "    sequential2_sum_impl(len(offsets),\n",
    "                         len(parents),\n",
    "                         <int32_t*>(<size_t>parents.ctypes.data),\n",
    "                         <float*>(<size_t>content.ctypes.data),\n",
    "                         <float*>(<size_t>output.ctypes.data))\n",
    "\n",
    "def sequential2_max(offsets, parents, content, output):\n",
    "    sequential2_max_impl(len(offsets),\n",
    "                         len(parents),\n",
    "                         <int32_t*>(<size_t>parents.ctypes.data),\n",
    "                         <float*>(<size_t>content.ctypes.data),\n",
    "                         <float*>(<size_t>output.ctypes.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def verify_correct(averagesize, run, which, location=\"/tmp/DATA\"):\n",
    "    offsets, parents, content = get_dataset(averagesize, location=location)\n",
    "    output = numpy.empty(len(offsets) - 1, dtype=numpy.float32)\n",
    "    run(offsets, parents, content, output)\n",
    "    original = numpy.fromfile(open(os.path.join(location, \"{}-{}\".format(which, averagesize)), \"rb\"),\n",
    "                              dtype=numpy.float32)\n",
    "    mask1 = numpy.isfinite(output)\n",
    "    mask2 = numpy.isfinite(original)\n",
    "    if not numpy.array_equal(mask1, mask2) or numpy.absolute(output[mask1] - original[mask2]).max() > 1e-5:\n",
    "        print(\"averagesize {} {} is not correct\".format(averagesize, which))\n",
    "        return offsets, parents, content, output, original\n",
    "    del offsets, parents, content, output, original\n",
    "    gc.collect()\n",
    "    return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for averagesize in averagesizes:\n",
    "    offsets, parents, content, output, original = verify_correct(averagesize, sequential2_sum, \"sum\")\n",
    "    if output is not None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for averagesize in averagesizes:\n",
    "    offsets, parents, content, output, original = verify_correct(averagesize, sequential2_max, \"max\")\n",
    "    if output is not None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
